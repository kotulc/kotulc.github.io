---
layout: default
---

# About Me

One important lesson that I have learned working in technology is that you are never finished learning.  New standards, systems, problems and opportunities are the norm in this environment.  If there is one consistent thread tying my personal, professional, and academic lives together, it's the act of exploring a previously mysterious domain and finding new insights, challenges, and rewards that enrich my understanding of the world.  I have found that active, hands-on exploration is one of the most effective ways to learn a new skill or trade and that working in this field is more of a continuing journey than a lone mountain to be climbed and conquered.

*Professionally,* working in an environment where approaching issues and projects requires a mix of technical, communication, and collaborative skills has shaped my problem solving approach. Collecting information, troubleshooting, design, and implementation all rely on consistent communication between any and all parties involved in the process. In my opinion, communication is possibly the most important skill for any technologist; though it is often one of the most overlooked.

*Recently,* I have found an interest in visualization tools and techniques as a means of improving ones intuition when it comes to working with large or complex data sets. Using motion to convey sequential information was the motivation for my [Matplotlib based animation project](https://kotulc.github.io/visualizations). Animating a graph or plot is nothing new, however this solution focuses on animating a standard set of components used in the context of Neural Networks. This set of tools allows users to combine individual components and display network information concurrently.

The problem with most visualizations is one of scale. It is difficult to scale and generalize visual representations between various applications. For Neural Networks in particular, there is a vast collection of visualization tools available depending on the area of focus, for example [OpenAI's Microscope](https://openai.com/blog/microscope/) and [Google Research's Lucid](https://distill.pub/2018/building-blocks/) [(source)](https://github.com/tensorflow/lucid/). Interpretability is an active area of research in machine learning and visualizations will play a key role in shedding light on systems that might otherwise be viewed as a black box. I have several [Jupyter Notebooks](https://kotulc.github.io/notebooks) with a few samples of my work in machine learning and visualization.

For more information regarding employment, references, or any of my work, the best way to contact me is through [Linkedin](https://www.linkedin.com/in/clayton-kotulak/)